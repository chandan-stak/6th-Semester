Microsoft Windows [Version 10.0.19042.985]
(c) Microsoft Corporation. All rights reserved.

C:\Users\chand>cd C:\hadoop-3.3.0.tar\hadoop-3.3.0\hadoop-3.3.0\sbin

C:\hadoop-3.3.0.tar\hadoop-3.3.0\hadoop-3.3.0\sbin>start-dfs

C:\hadoop-3.3.0.tar\hadoop-3.3.0\hadoop-3.3.0\sbin>start-yarn
starting yarn daemons

C:\hadoop-3.3.0.tar\hadoop-3.3.0\hadoop-3.3.0\sbin>jps
14724 DataNode
25252 ResourceManager
27124 NameNode
13464 Jps
13084 NodeManager

C:\hadoop-3.3.0.tar\hadoop-3.3.0\hadoop-3.3.0\sbin>hdfs dfs -ls /
Found 2 items
drwxr-xr-x   - chand supergroup          0 2021-06-03 23:30 /input_dir
drwx------   - chand supergroup          0 2021-06-03 23:34 /tmp

C:\hadoop-3.3.0.tar\hadoop-3.3.0\hadoop-3.3.0\sbin>hdfs dfs -cat /input_dir/input.txt
Hello This is Chandan C Bagan
Stay home
Stay Safe

C:\hadoop-3.3.0.tar\hadoop-3.3.0\hadoop-3.3.0\sbin>hadoop jar E:\Academics\6th_sem\BDA\Lab\BDA_1BM18CS026\Lab_6\sort.jar samples.topn.TopN /input_dir/input.txt /output_dir
2021-06-04 16:54:31,983 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2021-06-04 16:54:32,073 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-06-04 16:54:32,073 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2021-06-04 16:54:32,664 INFO input.FileInputFormat: Total input files to process : 1
2021-06-04 16:54:32,827 INFO mapreduce.JobSubmitter: number of splits:1
2021-06-04 16:54:33,653 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1890198064_0001
2021-06-04 16:54:33,653 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-06-04 16:54:33,953 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
2021-06-04 16:54:33,955 INFO mapreduce.Job: Running job: job_local1890198064_0001
2021-06-04 16:54:33,957 INFO mapred.LocalJobRunner: OutputCommitter set in config null
2021-06-04 16:54:33,979 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2021-06-04 16:54:33,980 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-06-04 16:54:33,980 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-06-04 16:54:34,173 INFO mapred.LocalJobRunner: Waiting for map tasks
2021-06-04 16:54:34,174 INFO mapred.LocalJobRunner: Starting task: attempt_local1890198064_0001_m_000000_0
2021-06-04 16:54:34,219 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2021-06-04 16:54:34,219 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-06-04 16:54:34,231 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
2021-06-04 16:54:34,358 INFO mapred.Task:  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@49b14446
2021-06-04 16:54:34,379 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/input_dir/input.txt:0+54
2021-06-04 16:54:34,606 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2021-06-04 16:54:34,607 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
2021-06-04 16:54:34,608 INFO mapred.MapTask: soft limit at 83886080
2021-06-04 16:54:34,610 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
2021-06-04 16:54:34,612 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
2021-06-04 16:54:34,623 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-06-04 16:54:34,906 INFO mapred.LocalJobRunner:
2021-06-04 16:54:34,910 INFO mapred.MapTask: Starting flush of map output
2021-06-04 16:54:34,911 INFO mapred.MapTask: Spilling map output
2021-06-04 16:54:34,916 INFO mapred.MapTask: bufstart = 0; bufend = 90; bufvoid = 104857600
2021-06-04 16:54:34,917 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214360(104857440); length = 37/6553600
2021-06-04 16:54:34,947 INFO mapred.MapTask: Finished spill 0
2021-06-04 16:54:34,968 INFO mapred.Task: Task:attempt_local1890198064_0001_m_000000_0 is done. And is in the process of committing
2021-06-04 16:54:34,974 INFO mapred.LocalJobRunner: map
2021-06-04 16:54:34,974 INFO mapred.Task: Task 'attempt_local1890198064_0001_m_000000_0' done.
2021-06-04 16:54:34,984 INFO mapred.Task: Final Counters for attempt_local1890198064_0001_m_000000_0: Counters: 23
        File System Counters
                FILE: Number of bytes read=8398
                FILE: Number of bytes written=622234
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=54
                HDFS: Number of bytes written=0
                HDFS: Number of read operations=5
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=1
                HDFS: Number of bytes read erasure-coded=0
        Map-Reduce Framework
                Map input records=3
                Map output records=10
                Map output bytes=90
                Map output materialized bytes=116
                Input split bytes=106
                Combine input records=0
                Spilled Records=10
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=293076992
        File Input Format Counters
                Bytes Read=54
2021-06-04 16:54:34,984 INFO mapred.LocalJobRunner: Finishing task: attempt_local1890198064_0001_m_000000_0
2021-06-04 16:54:34,987 INFO mapred.LocalJobRunner: map task executor complete.
2021-06-04 16:54:34,988 INFO mapreduce.Job: Job job_local1890198064_0001 running in uber mode : false
2021-06-04 16:54:34,991 INFO mapred.LocalJobRunner: Waiting for reduce tasks
2021-06-04 16:54:34,995 INFO mapred.LocalJobRunner: Starting task: attempt_local1890198064_0001_r_000000_0
2021-06-04 16:54:34,996 INFO mapreduce.Job:  map 100% reduce 0%
2021-06-04 16:54:35,012 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2021-06-04 16:54:35,022 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-06-04 16:54:35,031 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
2021-06-04 16:54:35,109 INFO mapred.Task:  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@311f52e5
2021-06-04 16:54:35,118 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7e119322
2021-06-04 16:54:35,121 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2021-06-04 16:54:35,157 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-06-04 16:54:35,162 INFO reduce.EventFetcher: attempt_local1890198064_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-06-04 16:54:35,198 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1890198064_0001_m_000000_0 decomp: 112 len: 116 to MEMORY
2021-06-04 16:54:35,218 INFO reduce.InMemoryMapOutput: Read 112 bytes from map-output for attempt_local1890198064_0001_m_000000_0
2021-06-04 16:54:35,220 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 112, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->112
2021-06-04 16:54:35,239 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
2021-06-04 16:54:35,241 INFO mapred.LocalJobRunner: 1 / 1 copied.
2021-06-04 16:54:35,245 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-06-04 16:54:35,263 INFO mapred.Merger: Merging 1 sorted segments
2021-06-04 16:54:35,263 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 104 bytes
2021-06-04 16:54:35,266 INFO reduce.MergeManagerImpl: Merged 1 segments, 112 bytes to disk to satisfy reduce memory limit
2021-06-04 16:54:35,275 INFO reduce.MergeManagerImpl: Merging 1 files, 116 bytes from disk
2021-06-04 16:54:35,277 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2021-06-04 16:54:35,277 INFO mapred.Merger: Merging 1 sorted segments
2021-06-04 16:54:35,286 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 104 bytes
2021-06-04 16:54:35,287 INFO mapred.LocalJobRunner: 1 / 1 copied.
2021-06-04 16:54:35,467 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-06-04 16:54:36,111 INFO mapred.Task: Task:attempt_local1890198064_0001_r_000000_0 is done. And is in the process of committing
2021-06-04 16:54:36,115 INFO mapred.LocalJobRunner: 1 / 1 copied.
2021-06-04 16:54:36,116 INFO mapred.Task: Task attempt_local1890198064_0001_r_000000_0 is allowed to commit now
2021-06-04 16:54:36,175 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1890198064_0001_r_000000_0' to hdfs://localhost:9000/output_dir
2021-06-04 16:54:36,177 INFO mapred.LocalJobRunner: reduce > reduce
2021-06-04 16:54:36,179 INFO mapred.Task: Task 'attempt_local1890198064_0001_r_000000_0' done.
2021-06-04 16:54:36,187 INFO mapred.Task: Final Counters for attempt_local1890198064_0001_r_000000_0: Counters: 30
        File System Counters
                FILE: Number of bytes read=8662
                FILE: Number of bytes written=622350
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=54
                HDFS: Number of bytes written=63
                HDFS: Number of read operations=10
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=3
                HDFS: Number of bytes read erasure-coded=0
        Map-Reduce Framework
                Combine input records=0
                Combine output records=0
                Reduce input groups=9
                Reduce shuffle bytes=116
                Reduce input records=10
                Reduce output records=9
                Spilled Records=10
                Shuffled Maps =1
                Failed Shuffles=0
                Merged Map outputs=1
                GC time elapsed (ms)=10
                Total committed heap usage (bytes)=293076992
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Output Format Counters
                Bytes Written=63
2021-06-04 16:54:36,188 INFO mapred.LocalJobRunner: Finishing task: attempt_local1890198064_0001_r_000000_0
2021-06-04 16:54:36,188 INFO mapred.LocalJobRunner: reduce task executor complete.
2021-06-04 16:54:37,011 INFO mapreduce.Job:  map 100% reduce 100%
2021-06-04 16:54:37,012 INFO mapreduce.Job: Job job_local1890198064_0001 completed successfully
2021-06-04 16:54:37,024 INFO mapreduce.Job: Counters: 36
        File System Counters
                FILE: Number of bytes read=17060
                FILE: Number of bytes written=1244584
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=108
                HDFS: Number of bytes written=63
                HDFS: Number of read operations=15
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=4
                HDFS: Number of bytes read erasure-coded=0
        Map-Reduce Framework
                Map input records=3
                Map output records=10
                Map output bytes=90
                Map output materialized bytes=116
                Input split bytes=106
                Combine input records=0
                Combine output records=0
                Reduce input groups=9
                Reduce shuffle bytes=116
                Reduce input records=10
                Reduce output records=9
                Spilled Records=20
                Shuffled Maps =1
                Failed Shuffles=0
                Merged Map outputs=1
                GC time elapsed (ms)=10
                Total committed heap usage (bytes)=586153984
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=54
        File Output Format Counters
                Bytes Written=63

C:\hadoop-3.3.0.tar\hadoop-3.3.0\hadoop-3.3.0\sbin>hdfs dfs -cat /output_dir/*
stay    2
c       1
chandan 1
bagan   1
is      1
this    1
hello   1
safe    1
home    1

C:\hadoop-3.3.0.tar\hadoop-3.3.0\hadoop-3.3.0\sbin>